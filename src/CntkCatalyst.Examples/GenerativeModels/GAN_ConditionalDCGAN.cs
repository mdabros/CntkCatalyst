using System;
using System.Collections.Generic;
using System.Diagnostics;
using System.IO;
using System.Linq;
using System.Windows;
using CNTK;
using CntkCatalyst.LayerFunctions;
using Microsoft.VisualStudio.TestTools.UnitTesting;

namespace CntkCatalyst.Examples.GenerativeModels
{
    /// <summary>
    /// Example based on:
    /// https://cntk.ai/pythondocs/CNTK_206B_DCGAN.html
    /// 
    /// Training follows the original paper relatively closely:
    /// Original GAN paper: https://arxiv.org/pdf/1406.2661v1.pdf
    /// DCGAN paper: https://arxiv.org/pdf/1511.06434.pdf
    /// 
    /// This example needs manual download of the MNIST dataset in CNTK format.
    /// Instruction on how to download and convert the dataset can be found here:
    /// https://github.com/Microsoft/CNTK/tree/master/Examples/Image/DataSets/MNIST
    /// </summary>
    [TestClass]
    public class GAN_ConditionalDCGAN
    {
        [TestMethod]
        public void Run()
        {
            // Prepare data
            var baseDataDirectoryPath = @"J:\Datasets\MNIST";
            var trainFilePath = Path.Combine(baseDataDirectoryPath, "Train-28x28_cntk_text.txt");

            // Define data type and device for the model.
            var dataType = DataType.Float;
            var device = DeviceDescriptor.UseDefaultDevice();

            // Setup initializers
            var random = new Random(232);
            Func<CNTKDictionary> weightInit = () => Initializers.Xavier(random.Next(), scale: 0.02);
            var biasInit = Initializers.Zero();

            // Ensure reproducible results with CNTK.
            CNTKLib.SetFixedRandomSeed((uint)random.Next());
            CNTKLib.ForceDeterministicAlgorithms();

            // Setup generator
            var classCount = 10;
            var codeShape = NDShape.CreateNDShape(new int[] { classCount });

            var ganeratorInputShape = NDShape.CreateNDShape(new int[] { 100 });
            var generatorInput = Variable.InputVariable(ganeratorInputShape, dataType);
            var generatorCode = Variable.InputVariable(codeShape, dataType);
            var generatorNetwork = Generator(generatorInput, generatorCode, 
                weightInit, biasInit, device, dataType);

            // Setup discriminator            
            var discriminatorInputShape = NDShape.CreateNDShape(new int[] { 784 }); // 28 * 28 * 1.
            var discriminatorInput = Variable.InputVariable(discriminatorInputShape, dataType);
            var discriminatorCode = Variable.InputVariable(codeShape, dataType);
            // scale image input between -1.0 and 1.0.
            var discriminatorInputScaled = CNTKLib.Minus(
                CNTKLib.ElementTimes(Constant.Scalar(2 * 0.00390625f, device), discriminatorInput),
                Constant.Scalar(1.0f, device));

            var discriminatorNetwork = Discriminator(discriminatorInputScaled, discriminatorCode,
                weightInit, biasInit, device, dataType);

            // The discriminator must be used on both the real MNIST images and fake images generated by the generator function.
            // One way to represent this in the computational graph is to create a clone of the output of the discriminator function, 
            // but with substituted inputs. Setting method = share in the clone function ensures that both paths through the discriminator model 
            // use the same set of parameters.
            var discriminatorNetworkFake = discriminatorNetwork
                .Clone(ParameterCloningMethod.Share, replacements:
                    new Dictionary<Variable, Variable>
                    {
                        { discriminatorInputScaled.Output, generatorNetwork.Output },
                        { discriminatorCode, generatorCode },
                    });

            // Create minibatch source for providing the real images.
            var imageNameToVariable = new Dictionary<string, Variable>
            {
                { "features", discriminatorInput },
                { "labels", discriminatorCode }
            };
            var imageAndLabelsMinibatchSource = CreateMinibatchSource(trainFilePath, imageNameToVariable, randomize: true);

            // Create minibatch source for providing the noise.
            var noiseNameToVariable = new Dictionary<string, Variable> { { "noise", generatorInput } };
            var noiseMinibatchSource = new UniformNoiseMinibatchSource(noiseNameToVariable, min: -1.0f, max: 1.0f, seed: random.Next());

            var codeNameToVariable = new Dictionary<string, Variable> { { "code", generatorCode } };
            var codeMinibatchSource = new RandomOneHotMinibatchSource(codeNameToVariable, classCount: classCount, seed: random.Next());

            var generatorMinibatchSource = new CompositeMinibatchSource(noiseMinibatchSource, codeMinibatchSource);

            // Combine both sources in the composite minibatch source.
            var discriminatorMinibatchSource = new CompositeMinibatchSource(imageAndLabelsMinibatchSource, 
                noiseMinibatchSource, codeMinibatchSource);

            // Setup generator loss: 1.0 - C.log(D_fake).
            var generatorLossFunc = CNTKLib.Minus(Constant.Scalar(1.0f, device), 
                CNTKLib.Log(discriminatorNetworkFake));
                        
            // Setup discriminator loss: -(C.log(D_real) + C.log(1.0 - D_fake)).
            var discriminatorLossFunc = CNTKLib.Negate(CNTKLib.Plus(CNTKLib.Log(discriminatorNetwork), 
                CNTKLib.Log(CNTKLib.Minus(Constant.Scalar(1.0f, device), discriminatorNetworkFake))));

            // Create fitters for the training loop.
            // Generator uses Adam and discriminator SGD. 
            // Advice from: https://github.com/soumith/ganhacks
            var generatorLearner = Learners.Adam(generatorNetwork.Parameters(), 
                learningRate: 0.0002, momentum: 0.5, gradientClippingThresholdPerSample: 1.0);
            var generatorFitter = CreateFitter(generatorLearner, generatorNetwork, generatorLossFunc, device);

            var discriminatorLearner = Learners.SGD(discriminatorNetwork.Parameters(), 
                learningRate: 0.0002, gradientClippingThresholdPerSample: 1.0);
            var discriminatorFitter = CreateFitter(discriminatorLearner, discriminatorNetwork, discriminatorLossFunc, device);

            int epochs = 8;
            int batchSize = 256;

            // Controls how many steps the discriminator takes, 
            // each time the generator takes 1 step.
            // Default from the original paper is 1.
            int discriminatorSteps = 1;

            var isSweepEnd = false;
            for (int epoch = 0; epoch < epochs;)
            {
                for (int step = 0; step < discriminatorSteps; step++)
                {
                    // Discriminator needs both real images and noise, 
                    // so uses the composite minibatch source.
                    var discriminatorMinibatchItems = discriminatorMinibatchSource.GetNextMinibatch(batchSize, device);
                    isSweepEnd = discriminatorMinibatchItems.isSweepEnd;

                    discriminatorFitter.FitNextStep(discriminatorMinibatchItems.minibatch, batchSize);
                    DisposeValues(discriminatorMinibatchItems.minibatch);
                }

                // Generator only needs noise images, 
                // so uses the noise minibatch source separately.
                var generatorMinibatchItems = generatorMinibatchSource.GetNextMinibatch(batchSize, device);

                generatorFitter.FitNextStep(generatorMinibatchItems.minibatch, batchSize);
                DisposeValues(generatorMinibatchItems.minibatch);

                if (isSweepEnd)
                {
                    var generatorCurrentLoss = generatorFitter.CurrentLoss;
                    generatorFitter.ResetLossAndMetricAccumulators();

                    var discriminatorCurrentLoss = discriminatorFitter.CurrentLoss;
                    discriminatorFitter.ResetLossAndMetricAccumulators();

                    var traceOutput = $"Epoch: {epoch + 1:000} Generator Loss = {generatorCurrentLoss:F8}, Discriminator Loss = {discriminatorCurrentLoss:F8}";
                    Trace.WriteLine(traceOutput);

                    ++epoch;
                }
            }

            // Sample 6x6 images from generator.
            // Only use the noise and code generating minibatch sources.
            var samples = 6 * 6;
            var batch = generatorMinibatchSource.GetNextMinibatch(samples, device);
            var noiseAndCode = batch.minibatch;

            var predictor = new Predictor(generatorNetwork, device);
            var images = predictor.PredictNextStep(noiseAndCode);
            var imagesData = images.SelectMany(t => t).ToArray();

            // Show examples
            var app = new Application();
            var window = new PlotWindowBitMap("Generated Images", imagesData, 28, 28, 1, true);
            window.Show();
            app.Run(window);
        }

        Function Generator(Function input, Variable conditionalCodeVariable,
            Func<CNTKDictionary> weightInit, CNTKDictionary biasInit,
            DeviceDescriptor device, DataType dataType)
        {
            var inputAndCode = new VariableVector { input, conditionalCodeVariable };

            // Combine the input and the conditional code.
            var generatorNetwork = CNTKLib.Splice(inputAndCode, new Axis(0));

            generatorNetwork = generatorNetwork
                 .Dense(1024, weightInit(), biasInit, device, dataType)
                 .BatchNorm(BatchNorm.Regular, device, dataType)
                 .ReLU()

                 .Dense(7 * 7 * 128, weightInit(), biasInit, device, dataType)
                 .BatchNorm(BatchNorm.Regular, device, dataType)
                 .ReLU()
                 .Reshape(NDShape.CreateNDShape(new int[] { 7, 7, 128 }))

                 .ConvTranspose2D((5, 5), 128, (2, 2), Padding.Zeros, (14, 14), weightInit(), biasInit, device, dataType)
                 .BatchNorm(BatchNorm.Spatial, device, dataType)
                 .ReLU()

                 .ConvTranspose2D((5, 5), 1, (2, 2), Padding.Zeros, (28, 28), weightInit(), biasInit, device, dataType)
                 .Tanh();

            Trace.Write(Model.Summary(generatorNetwork));

            return generatorNetwork.Reshape(NDShape.CreateNDShape(new int[] { 784 }));
        }

        Function Discriminator(Function inputImageVariable, Variable conditionalCodeVariable,
            Func<CNTKDictionary> weightInit, CNTKDictionary biasInit,
            DeviceDescriptor device, DataType dataType)
        {
            var imageNetwork = inputImageVariable
                 .Reshape(NDShape.CreateNDShape(new int[] { 28, 28, 1 }))

                 .Conv2D((5, 5), 1, (2, 2), Padding.None, weightInit(), biasInit, device, dataType)
                 .BatchNorm(BatchNorm.Spatial, device, dataType)
                 .LeakyReLU(0.2)

                 .Conv2D((5, 5), 64, (2, 2), Padding.None, weightInit(), biasInit, device, dataType)
                 .BatchNorm(BatchNorm.Spatial, device, dataType)
                 .LeakyReLU(0.2)

                 .Dense(1024, weightInit(), biasInit, device, dataType)
                 .BatchNorm(BatchNorm.Regular, device, dataType)
                 .LeakyReLU(0.2);

            // Combine the image network with the conditional code.
            var imageAndCode = new VariableVector { imageNetwork, conditionalCodeVariable };
            var descriminatorNetwork = CNTKLib.Splice(imageAndCode, new Axis(0));

            descriminatorNetwork = descriminatorNetwork
                .Dense(1024, weightInit(), biasInit, device, dataType)
                .BatchNorm(BatchNorm.Regular, device, dataType)
                .LeakyReLU(0.2)

            .Dense(1, weightInit(), biasInit, device, dataType)
            .Sigmoid();

            Trace.Write(Model.Summary(imageNetwork));

            return descriminatorNetwork;
        }

        CntkMinibatchSource CreateMinibatchSource(string mapFilePath, Dictionary<string, Variable> nameToVariable,
            bool randomize)
        {
            var streamConfigurations = new List<StreamConfiguration>();
            foreach (var kvp in nameToVariable)
            {
                var size = kvp.Value.Shape.TotalSize;
                var name = kvp.Key;
                streamConfigurations.Add(new StreamConfiguration(name, size));
            }

            var minibatchSource = MinibatchSource.TextFormatMinibatchSource(
                mapFilePath,
                streamConfigurations,
                MinibatchSource.InfinitelyRepeat,
                randomize);

            return new CntkMinibatchSource(minibatchSource, nameToVariable);
        }

        static Fitter CreateFitter(Learner learner, Function network, Function loss, DeviceDescriptor device)
        {            
            var trainer = Trainer.CreateTrainer(network, loss, loss, new List<Learner> { learner });
            var fitter = new Fitter(trainer, device);

            return fitter;
        }

        void DisposeValues(IDictionary<Variable, Value> minibatch)
        {
            foreach (var value in minibatch.Values)
            {
                value.Dispose();
            }
        }
    }
}
