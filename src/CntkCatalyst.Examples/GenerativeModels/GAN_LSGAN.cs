using System;
using System.Collections.Generic;
using System.Diagnostics;
using System.IO;
using System.Linq;
using System.Windows;
using CNTK;
using CntkCatalyst.LayerFunctions;
using Microsoft.VisualStudio.TestTools.UnitTesting;

namespace CntkCatalyst.Examples.GenerativeModels
{
    /// <summary>
    /// Example based on:
    /// https://cntk.ai/pythondocs/CNTK_206C_WGAN_LSGAN.html
    /// 
    /// Training follows the original paper relatively closely:
    /// Original GAN paper: https://arxiv.org/pdf/1406.2661v1.pdf
    /// LS-GAN paper: https://arxiv.org/pdf/1701.06264.pdf
    /// 
    /// This example needs manual download of the CIFAR-10 dataset in CNTK format.
    /// Instruction on how to download and convert the dataset can be found here:
    /// https://github.com/Microsoft/CNTK/tree/master/Examples/Image/DataSets/CIFAR-10
    /// </summary>
    [TestClass]
    public class GAN_LSGAN
    {
        [TestMethod]
        public void Run()
        {
            // Prepare data
            var baseDataDirectoryPath = @"E:\DataSets\CIFAR10";
            var trainFilePath = Path.Combine(baseDataDirectoryPath, "Train_cntk_text.txt");

            // Define data type and device for the model.
            var dataType = DataType.Float;
            var device = DeviceDescriptor.UseDefaultDevice();

            // Setup initializers
            var random = new Random(232);
            Func<CNTKDictionary> weightInit = () => Initializers.Xavier(random.Next(), scale: 0.02);
            var biasInit = Initializers.Zero();

            // Ensure reproducible results with CNTK.
            CNTKLib.SetFixedRandomSeed((uint)random.Next());
            CNTKLib.ForceDeterministicAlgorithms();

            // Setup generator
            var ganeratorInputShape = NDShape.CreateNDShape(new int[] { 100 });
            var generatorInput = Variable.InputVariable(ganeratorInputShape, dataType);
            var generatorNetwork = Generator(generatorInput, weightInit, biasInit, device, dataType);

            // Setup discriminator            
            var discriminatorInputShape = NDShape.CreateNDShape(new int[] { 32 * 32 * 3 });
            var discriminatorInput = Variable.InputVariable(discriminatorInputShape, dataType);
            // scale image input between -1.0 and 1.0.
            var discriminatorInputScaled = CNTKLib.Minus(
                CNTKLib.ElementTimes(Constant.Scalar(2 * 0.00390625f, device), discriminatorInput),
                Constant.Scalar(1.0f, device));

            var discriminatorNetwork = Discriminator(discriminatorInputScaled, weightInit, biasInit, device, dataType);

            // The discriminator must be used on both the real CIFAR images and fake images generated by the generator function.
            // One way to represent this in the computational graph is to create a clone of the output of the discriminator function, 
            // but with substituted inputs. Setting method = share in the clone function ensures that both paths through the discriminator model 
            // use the same set of parameters.
            var discriminatorNetworkFake = discriminatorNetwork
                .Clone(ParameterCloningMethod.Share, replacements:
                    new Dictionary<Variable, Variable>
                    {
                        { discriminatorInputScaled.Output, generatorNetwork.Output },
                    });

            // Create minibatch source for providing the real images.
            var imageNameToVariable = new Dictionary<string, Variable> { { "features", discriminatorInput } };
            var imageMinibatchSource = CreateMinibatchSource(trainFilePath, imageNameToVariable, randomize: true);

            // Create minibatch source for providing the noise.
            var noiseNameToVariable = new Dictionary<string, Variable> { { "noise", generatorInput } };
            var noiseMinibatchSource = new UniformNoiseMinibatchSource(noiseNameToVariable, min: -1.0f, max: 1.0f, seed: random.Next());

            // Combine both sources in the composite minibatch source.
            var compositeMinibatchSource = new CompositeMinibatchSource(imageMinibatchSource, noiseMinibatchSource);

            // Setup generator loss: D_fake
            var generatorLossFunc = discriminatorNetworkFake;

            // Setup discriminator loss: C.element_max(D_real - D_fake + lambda_ * C.reduce_sum(C.abs(X_fake - X_real_scaled)), [0.])
            const float lampda = 0.0002f;
            var value = CNTKLib.Plus(CNTKLib.Minus(discriminatorNetwork, discriminatorNetworkFake), CNTKLib.MatMul(Constant.Scalar(lampda, device), CNTKLib.ReduceSum(CNTKLib.Abs(CNTKLib.Minus(generatorNetwork, discriminatorInputScaled)), new Axis(0))));
            var zero = Constant.Scalar(0.0f, device);
            var discriminatorLossFunc = CNTKLib.ElementMax(value, zero, "discriminatorLoss");
                
                //CNTKLib.Plus(discriminatorNetwork, discriminatorNetworkFake);

            var generatorLearner = Learners.Adam(generatorNetwork.Parameters(),
                learningRate: 0.0001, momentum: 0.5, varianceMomentum: 0.999, 
                    l2Regularization: 0.00005, unitGain: false);
            var generatorFitter = CreateFitter(generatorLearner, generatorNetwork, generatorLossFunc, device);

            var discriminatorLearner = Learners.Adam(discriminatorNetwork.Parameters(),
                learningRate: 0.0001, momentum: 0.0, varianceMomentum: 0.999,
                    l2Regularization: 0.00005, unitGain: false);
            var discriminatorFitter = CreateFitter(discriminatorLearner, discriminatorNetwork, discriminatorLossFunc, device);

            int epochs = 30;
            int batchSize = 64;

            var isSweepEnd = false;
            for (int epoch = 0; epoch < epochs;)
            {

                // Discriminator needs both real images and noise, 
                // so uses the composite minibatch source.
                var minibatchItems = compositeMinibatchSource.GetNextMinibatch(batchSize, device);
                isSweepEnd = minibatchItems.isSweepEnd;

                discriminatorFitter.FitNextStep(minibatchItems.minibatch, batchSize);
                DisposeValues(minibatchItems.minibatch);

                // Generator only needs noise images, 
                // so uses the noise minibatch source separately.
                var noiseMinibatchItems = noiseMinibatchSource.GetNextMinibatch(batchSize, device);

                generatorFitter.FitNextStep(noiseMinibatchItems.minibatch, batchSize);
                DisposeValues(noiseMinibatchItems.minibatch);

                // Temp trace of loss pr. minibatch.
                Trace.WriteLine($"Generator Loss = {generatorFitter.CurrentLoss:F8}, Discriminator Loss = {discriminatorFitter.CurrentLoss:F8}");

                if (isSweepEnd)
                {
                    var generatorCurrentLoss = generatorFitter.CurrentLoss;
                    generatorFitter.ResetLossAndMetricAccumulators();

                    var discriminatorCurrentLoss = discriminatorFitter.CurrentLoss;
                    discriminatorFitter.ResetLossAndMetricAccumulators();

                    var traceOutput = $"Epoch: {epoch + 1:000} Generator Loss = {generatorCurrentLoss:F8}, Discriminator Loss = {discriminatorCurrentLoss:F8}";
                    Trace.WriteLine(traceOutput);

                    ++epoch;
                }
            }

            // Sample 6x6 images from generator.
            var samples = 6 * 6;
            var batch = noiseMinibatchSource.GetNextMinibatch(samples, device);
            var noise = batch.minibatch;

            var predictor = new Predictor(generatorNetwork, device);
            var images = predictor.PredictNextStep(noise);
            var imagesData = images.SelectMany(t => t).ToArray();

            // Show examples
            var app = new Application();
            var window = new PlotWindowBitMap("Generated Images", imagesData, 32, 32, 3, true);
            window.Show();
            app.Run(window);
        }

        Function Generator(Function input, Func<CNTKDictionary> weightInit, CNTKDictionary biasInit,
            DeviceDescriptor device, DataType dataType)
        {
            var generatorNetwork = input
                 .Dense(4 * 4 * 256, weightInit(), biasInit, device, dataType)
                 .BatchNorm(BatchNorm.Regular, device, dataType)
                 .ReLU()

                 .Reshape(NDShape.CreateNDShape(new int[] { 4, 4, 256 }))

                 .ConvTranspose2D((5, 5), 128, (2, 2), Padding.Zeros, (8, 8), weightInit(), biasInit, device, dataType)
                 .BatchNorm(BatchNorm.Spatial, device, dataType)
                 .ReLU()

                 .ConvTranspose2D((5, 5), 64, (2, 2), Padding.Zeros, (16, 16), weightInit(), biasInit, device, dataType)
                 .BatchNorm(BatchNorm.Spatial, device, dataType)
                 .ReLU()

                 .ConvTranspose2D((5, 5), 3, (2, 2), Padding.Zeros, (32, 32), weightInit(), biasInit, device, dataType)
                 .Tanh();

            Trace.Write(Model.Summary(generatorNetwork));

            return generatorNetwork.Reshape(NDShape.CreateNDShape(new int[] { 32 * 32 * 3 }));
        }

        Function Discriminator(Function input, Func<CNTKDictionary> weightInit, CNTKDictionary biasInit,
            DeviceDescriptor device, DataType dataType)
        {
            var discriminatorNetwork = input
                 .Reshape(NDShape.CreateNDShape(new int[] { 32, 32, 3 }))

                 .Conv2D((5, 5), 64, (2, 2), Padding.Zeros, weightInit(), biasInit, device, dataType)
                 //.BatchNorm(BatchNorm.Spatial, device, dataType)
                 .LeakyReLU(0.2)

                 .Conv2D((5, 5), 128, (2, 2), Padding.Zeros, weightInit(), biasInit, device, dataType)
                 .BatchNorm(BatchNorm.Spatial, device, dataType)
                 .LeakyReLU(0.2)

                 .Conv2D((5, 5), 256, (2, 2), Padding.Zeros, weightInit(), biasInit, device, dataType)
                 .BatchNorm(BatchNorm.Spatial, device, dataType)
                 .LeakyReLU(0.2)

                 .Dense(1, weightInit(), biasInit, device, dataType);

            Trace.Write(Model.Summary(discriminatorNetwork));

            return discriminatorNetwork;
        }

        CntkMinibatchSource CreateMinibatchSource(string mapFilePath, Dictionary<string, Variable> nameToVariable,
            bool randomize)
        {
            var streamConfigurations = new List<StreamConfiguration>();
            foreach (var kvp in nameToVariable)
            {
                var size = kvp.Value.Shape.TotalSize;
                var name = kvp.Key;
                streamConfigurations.Add(new StreamConfiguration(name, size));
            }

            var minibatchSource = MinibatchSource.TextFormatMinibatchSource(
                mapFilePath,
                streamConfigurations,
                MinibatchSource.InfinitelyRepeat,
                randomize);

            return new CntkMinibatchSource(minibatchSource, nameToVariable);
        }

        static Fitter CreateFitter(Learner learner, Function network, Function loss, DeviceDescriptor device)
        {
            var trainer = Trainer.CreateTrainer(network, loss, loss, new List<Learner> { learner });
            var fitter = new Fitter(trainer, device);

            return fitter;
        }

        void DisposeValues(IDictionary<Variable, Value> minibatch)
        {
            foreach (var value in minibatch.Values)
            {
                value.Dispose();
            }
        }
    }
}
